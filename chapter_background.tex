\chapter{Background}
\label{cha:background}
\section{Literature review}
There is plenty of research to suggest that using wearable activity trackers helps people become more physically active. A large systematic review has shown that, over a number of studies, there is significant increase in daily step count, moderate and vigorous activity as a result of using wearables \cite{trackersBenefitGeneral}. In particular, people with chronic illnesses experienced decreased systolic blood pressure, waist circumference, etc \cite {Franssen2020}; monitoring such patients using wearables after hospitalizations could help detect complications and prevent rehospitalization \cite{hospi}. People of older age can also benefit greatly, showing moderate increase in physical activity and mobility \cite{SOliveira1188}; there is indication of good acceptability of such devices among older adults \cite {Franssen2020}. Attractiveness, gamification, readability, feedback is what drives the health benefits such as commitment to daily physical activity \cite{NELSON2016364}. Wearables are not a magic bullet solution to fitness problem. Some studies that spanned larger periods of time have observed decrease in physical activity after an initial positive effect \cite{Finkelstein2016}, or in other words, use of wearable devices is not directly effective at modifying habitual behavior \cite{LI2021104487}. A number of examined devices did not report sensor accuracy output validity at all, allowing for overestimation or underestimation of metrics \cite{Lee2014ActivityTA}

\section{Similar Systems}
\label{section:similarSystems}
\subsection{Google Fit}
\subsection{Apple Health}
\subsection{Other}
\section{Devices Used}
\subsection{Withings}
\subsection{Oura}
\section{Cloud Infrastructure}
Using cloud for the software service infrastructure has the benefit of off-loading complexity to cloud providers instead of handling it yourself. The services they provided are characterized as follows \cite{cloudServicesCategories}: 
\begin{itemize}
    \item 
\end{itemize}

\subsection{Cloud Providers}
There are 3 major providers in this space: AWS, Azure and GCP. They fall into public cloud category, similar to utility services like Electricity, they are available for use to anyone, be it individual developer or a company. We are relying on third-parties to handle things such as legal compliance, disaster management etc. Providers outline their legal promises in the document called Service Level Agreement (SLA) \cite{cloudSLA}. Outlining major cloud provider's differences:
\begin{itemize}
    \item {he}
\end{itemize}

I chose AWS for this project for the following reasons:
\begin{itemize}
    \item{AWS has the best security system [cite], mainly due to IAM service, allowing for tight control of what a resource allowed to access in the infrastructure. }
    \item{if used under similar conditions, such as hosting the database in the same region in all comparisons, AWS has among the best quantative performance metrics, such as availability, latency etc \cite{CloudMetrics}  }
\end{itemize}
\subsection{Serverless}
\subsection{Security}
Software Security is important, especially in the context of this project that deals with sensitive health data. Generic web-accessible recommendations should apply to this project, such as encryption, xss, etc. However, deploying the application on the cloud presents new security related challenges, which a lot of companies suffer from [cite]. 
\section{LLMs}
"A large language model is the language model with massive
parameters that undergoes pretraining tasks (e.g., masked
language modeling and autoregressive prediction) to un-
derstand and process human language, by modeling the
contextualized text semantics and probabilities from large
amounts of text data " \cite{Yao2023ASO}
Unlike neural networks, the main way to improve response quality is to improve the prompt \cite{Liu2021PretrainPA}; "Prompt Engineering" is the technique for doing that, maximizing utility of LLMs in various tasks \cite{zhou2023large}
 In 2022, OpenAI made GPT3 available to the public, a product that surpassed Google in daily webpage visits. It revolutionized AI, in a way that a lay person could use it with some decent efficiency. The vital factor is it's ability to effectively utilize context window, a collection of prior information (such as prior messages sent in a chat) that is used to influence the next output. The workflow of using GPT3 as a software developer is as follows: Explicitly attach context messages together with a prompt. The complexity of managing contexts was upon your system that uses the OpenAI API. This recently changed with Assistants API. This feature allows creating of assistants, which can have threads that correspond to continuous chat with a user. Key factor is that the complexity of maintaining context is handled by OpenAI. Also it features OpenAI's own Retrieval Assisted Generation (RAG) solution named Knowledge Retrieval. RAG is a functionality that allows LLMs to access relevant external knowledge and use it for response generation. It is usually more prioritised that the ordinary context,significantly reducing the chances of hallucinations and improving output quality. [cite]

% On 4th March 2024, Shortly after finishing the project implementation, Anthropic announced Claude 3 Sonnet. It's benchmark scores are similar or better than gpt-4-1106-preview, it has bigger context window but costs 333\% less. This makes the reasoning behind the choice of gpt-4-1106-preview not valid at the moment of writing the report, however it was valid at the time of planning for AI functionality at the time of Dec 2023. 