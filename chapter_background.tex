\chapter{Background}
\label{cha:background}
\section{Literature review}
\subsection{Wearables}
\subsection{Nudging \& Fitness}
\subsection{Cloud}
\section{Similar Systems}
\label{section:similarSystems}
\subsection{Google Fit}
\subsection{Apple Health}
\subsection{Other}
\section{Devices Used}
\subsection{Withings}
\subsection{Oura}
\section{Cloud Infrastructure}
Using cloud for the software service infrastructure has the benefit of off-loading complexity to cloud providers instead of handling it yourself. The services they provided are characterized as follows \cite{cloudServicesCategories}: 
\begin{itemize}
    \item 
\end{itemize}
\subsection{Serverless vs Server}
\subsection{Cloud Providers}
There are 3 major providers in this space: AWS, Azure and GCP. They fall into public cloud category, similar to utility services like Electricity, they are available for use to anyone, be it individual developer or a company. We are relying on third-parties to handle things such as legal compliance, disaster management etc. Providers outline their legal promises in the document called Service Level Agreement (SLA) \cite{cloudSLA}. Outlining major cloud provider's differences:
\begin{itemize}
    \item {he}
\end{itemize}

I chose AWS for this project for the following reasons:
\begin{itemize}
    \item{AWS has the best security system [cite], mainly due to IAM service, allowing for tight control of what a resource allowed to access in the infrastructure. }
    \item{if used under similar conditions, such as hosting the database in the same region in all comparisons, AWS has among the best quantative performance metrics, such as availability, latency etc \cite{CloudMetrics}  }
\end{itemize}
\subsection{Security}
Software Security is important, especially in the context of this project that deals with sensitive health data. Generic web-accessible recommendations should apply to this project, such as encryption, xss, etc. However, deploying the application on the cloud presents new security related challenges, which a lot of companies suffer from [cite]. 
\section{LLMs - Practical application}
Because this project does not focus on machine learning, we will only talk about LLMs in practical sense, such as developer experience, performance etc, not their internal implementation details. In 2022, OpenAI made GPT3 available to the public, a product that surpassed Google in daily webpage visits. It revolutionized AI, in a way that a lay person could use it with some decent efficiency. The vital factor is it's ability to effectively utilize context window, a collection of prior information (such as prior messages sent in a chat) that is used to influence the next output. The workflow of using GPT3 as a software developer is as follows: Explicitly attach context messages together with a prompt. The complexity of managing contexts was upon your system that uses the OpenAI API. This recently changed with Assistants API. This feature allows creating of assistants, which can have threads that correspond to continuous chat with a user. Key factor is that the complexity of maintaining context is handled by OpenAI. Also it features OpenAI's own Retrieval Assisted Generation (RAG) solution named Knowledge Retrieval. RAG is a functionality that allows LLMs to access relevant external knowledge. One of the main benefits is cost saving, as it only includes relevant context, fitness data in this project in a generation request. For example, we want to use GPT4 to create a daily feedback that should use previous 7 days of fitness data.

On 4th March 2024, Shortly after finishing the project implementation, Anthropic announced Claude 3 Sonnet. It's benchmark scores are similar or better than gpt-4-1106-preview, it has bigger context window but costs 333\% less. This makes the reasoning behind the choice of gpt-4-1106-preview not valid at the moment of writing the report, however it was valid at the time of planning for AI functionality at the time of Dec 2023. 